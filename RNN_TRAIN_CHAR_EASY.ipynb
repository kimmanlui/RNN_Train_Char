{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This program runs on version 2.0.6\n",
      "keras version 2.0.6\n"
     ]
    }
   ],
   "source": [
    "## Train RNN for 1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9,0\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import keras\n",
    "\n",
    "\n",
    "#change the working directory \n",
    "os.chdir('/notebooks/torch')\n",
    "\n",
    "print(\"This program runs on version 2.0.6\")\n",
    "print(\"keras version \"+keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text=\"1234567890\"*10000\n",
    "targetText=text[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345678901\n"
     ]
    }
   ],
   "source": [
    "print(targetText[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = list(set(text))\n",
    "max_features = len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0, '0': 1, '3': 2, '2': 3, '5': 4, '4': 5, '7': 6, '6': 7, '9': 8, '8': 9}\n"
     ]
    }
   ],
   "source": [
    "mydict = [(dctElement, counter) for counter, dctElement in enumerate(dct)]\n",
    "mydict = dict(mydict)\n",
    "print(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_mydict = {v: k for k, v in mydict.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 93, 10)\n"
     ]
    }
   ],
   "source": [
    "tLen=93\n",
    "sRow=len(text)%tLen\n",
    "\n",
    "X=np.zeros( (sRow,tLen,max_features), dtype=int)\n",
    "y=np.zeros( (sRow,tLen,max_features), dtype=int)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(sRow) :\n",
    "    extract=text[i*tLen : i*tLen+tLen]\n",
    "    extracty=targetText[i*tLen : i*tLen+tLen]\n",
    "    for j in range(tLen) :\n",
    "        dexX=dct.index(extract[j])\n",
    "        dexy=dct.index(extracty[j])\n",
    "        X[i,j,dexX]=1\n",
    "        y[i,j,dexy]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 93, 10)\n",
      "[[1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]]\n",
      "(25, 93, 10)\n",
      "[[0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X[0,0:5,...])\n",
    "print(y.shape)\n",
    "print(y[0,0:5,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 93, 10)\n",
      "(25, 93, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 93, 10)\n",
      "(25, 93, 10)\n"
     ]
    }
   ],
   "source": [
    "# we don't split any. This block is not implemented\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.0, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model.\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "isCheckpoint=False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(None, max_features), return_sequences=True))\n",
    "#model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(Dense(max_features))  #is it dense? or add(LSTM(max_features))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "\n",
    "# It is a best practice to use checkpoint \n",
    "callbacks_list=None\n",
    "if isCheckpoint==True:\n",
    "  filepath=\"weight/RNN_BinaryAddition_Method_2-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "  checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "  callbacks_list = [checkpoint]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_history=[[],[]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21 samples, validate on 4 samples\n",
      "Epoch 1/300\n",
      "21/21 [==============================] - 0s - loss: 0.0821 - val_loss: 0.0812\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s - loss: 0.0816 - val_loss: 0.0807\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s - loss: 0.0811 - val_loss: 0.0802\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s - loss: 0.0806 - val_loss: 0.0797\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s - loss: 0.0801 - val_loss: 0.0792\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s - loss: 0.0796 - val_loss: 0.0787\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s - loss: 0.0791 - val_loss: 0.0782\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s - loss: 0.0785 - val_loss: 0.0777\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s - loss: 0.0780 - val_loss: 0.0772\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s - loss: 0.0774 - val_loss: 0.0767\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s - loss: 0.0769 - val_loss: 0.0761\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s - loss: 0.0763 - val_loss: 0.0756\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s - loss: 0.0758 - val_loss: 0.0750\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s - loss: 0.0752 - val_loss: 0.0745\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s - loss: 0.0746 - val_loss: 0.0739\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s - loss: 0.0740 - val_loss: 0.0733\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s - loss: 0.0734 - val_loss: 0.0728\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s - loss: 0.0728 - val_loss: 0.0722\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s - loss: 0.0722 - val_loss: 0.0716\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s - loss: 0.0716 - val_loss: 0.0710\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s - loss: 0.0710 - val_loss: 0.0705\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s - loss: 0.0704 - val_loss: 0.0699\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s - loss: 0.0698 - val_loss: 0.0693\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s - loss: 0.0691 - val_loss: 0.0687\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s - loss: 0.0685 - val_loss: 0.0681\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s - loss: 0.0679 - val_loss: 0.0675\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s - loss: 0.0672 - val_loss: 0.0669\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s - loss: 0.0666 - val_loss: 0.0663\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s - loss: 0.0660 - val_loss: 0.0657\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s - loss: 0.0653 - val_loss: 0.0651\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s - loss: 0.0647 - val_loss: 0.0645\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s - loss: 0.0640 - val_loss: 0.0638\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s - loss: 0.0634 - val_loss: 0.0633\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s - loss: 0.0627 - val_loss: 0.0626\n",
      "Epoch 35/300\n",
      "21/21 [==============================] - 0s - loss: 0.0621 - val_loss: 0.0621\n",
      "Epoch 36/300\n",
      "21/21 [==============================] - 0s - loss: 0.0614 - val_loss: 0.0614\n",
      "Epoch 37/300\n",
      "21/21 [==============================] - 0s - loss: 0.0608 - val_loss: 0.0608\n",
      "Epoch 38/300\n",
      "21/21 [==============================] - 0s - loss: 0.0601 - val_loss: 0.0602\n",
      "Epoch 39/300\n",
      "21/21 [==============================] - 0s - loss: 0.0595 - val_loss: 0.0596\n",
      "Epoch 40/300\n",
      "21/21 [==============================] - 0s - loss: 0.0588 - val_loss: 0.0589\n",
      "Epoch 41/300\n",
      "21/21 [==============================] - 0s - loss: 0.0582 - val_loss: 0.0584\n",
      "Epoch 42/300\n",
      "21/21 [==============================] - 0s - loss: 0.0576 - val_loss: 0.0577\n",
      "Epoch 43/300\n",
      "21/21 [==============================] - 0s - loss: 0.0570 - val_loss: 0.0573\n",
      "Epoch 44/300\n",
      "21/21 [==============================] - 0s - loss: 0.0563 - val_loss: 0.0566\n",
      "Epoch 45/300\n",
      "21/21 [==============================] - 0s - loss: 0.0557 - val_loss: 0.0561\n",
      "Epoch 46/300\n",
      "21/21 [==============================] - 0s - loss: 0.0551 - val_loss: 0.0554\n",
      "Epoch 47/300\n",
      "21/21 [==============================] - 0s - loss: 0.0545 - val_loss: 0.0550\n",
      "Epoch 48/300\n",
      "21/21 [==============================] - 0s - loss: 0.0540 - val_loss: 0.0544\n",
      "Epoch 49/300\n",
      "21/21 [==============================] - 0s - loss: 0.0535 - val_loss: 0.0542\n",
      "Epoch 50/300\n",
      "21/21 [==============================] - 0s - loss: 0.0530 - val_loss: 0.0536\n",
      "Epoch 51/300\n",
      "21/21 [==============================] - 0s - loss: 0.0527 - val_loss: 0.0535\n",
      "Epoch 52/300\n",
      "21/21 [==============================] - 0s - loss: 0.0523 - val_loss: 0.0530\n",
      "Epoch 53/300\n",
      "21/21 [==============================] - 0s - loss: 0.0521 - val_loss: 0.0531\n",
      "Epoch 54/300\n",
      "21/21 [==============================] - 0s - loss: 0.0518 - val_loss: 0.0528\n",
      "Epoch 55/300\n",
      "21/21 [==============================] - 0s - loss: 0.0519 - val_loss: 0.0528\n",
      "Epoch 56/300\n",
      "21/21 [==============================] - 0s - loss: 0.0515 - val_loss: 0.0522\n",
      "Epoch 57/300\n",
      "21/21 [==============================] - 0s - loss: 0.0513 - val_loss: 0.0514\n",
      "Epoch 58/300\n",
      "21/21 [==============================] - 0s - loss: 0.0500 - val_loss: 0.0497\n",
      "Epoch 59/300\n",
      "21/21 [==============================] - 0s - loss: 0.0487 - val_loss: 0.0485\n",
      "Epoch 60/300\n",
      "21/21 [==============================] - 0s - loss: 0.0472 - val_loss: 0.0476\n",
      "Epoch 61/300\n",
      "21/21 [==============================] - 0s - loss: 0.0464 - val_loss: 0.0471\n",
      "Epoch 62/300\n",
      "21/21 [==============================] - 0s - loss: 0.0459 - val_loss: 0.0466\n",
      "Epoch 63/300\n",
      "21/21 [==============================] - 0s - loss: 0.0453 - val_loss: 0.0461\n",
      "Epoch 64/300\n",
      "21/21 [==============================] - 0s - loss: 0.0448 - val_loss: 0.0456\n",
      "Epoch 65/300\n",
      "21/21 [==============================] - 0s - loss: 0.0443 - val_loss: 0.0451\n",
      "Epoch 66/300\n",
      "21/21 [==============================] - 0s - loss: 0.0438 - val_loss: 0.0446\n",
      "Epoch 67/300\n",
      "21/21 [==============================] - 0s - loss: 0.0433 - val_loss: 0.0441\n",
      "Epoch 68/300\n",
      "21/21 [==============================] - 0s - loss: 0.0428 - val_loss: 0.0436\n",
      "Epoch 69/300\n",
      "21/21 [==============================] - 0s - loss: 0.0423 - val_loss: 0.0432\n",
      "Epoch 70/300\n",
      "21/21 [==============================] - 0s - loss: 0.0418 - val_loss: 0.0426\n",
      "Epoch 71/300\n",
      "21/21 [==============================] - 0s - loss: 0.0414 - val_loss: 0.0423\n",
      "Epoch 72/300\n",
      "21/21 [==============================] - 0s - loss: 0.0409 - val_loss: 0.0417\n",
      "Epoch 73/300\n",
      "21/21 [==============================] - 0s - loss: 0.0405 - val_loss: 0.0415\n",
      "Epoch 74/300\n",
      "21/21 [==============================] - 0s - loss: 0.0401 - val_loss: 0.0411\n",
      "Epoch 75/300\n",
      "21/21 [==============================] - 0s - loss: 0.0398 - val_loss: 0.0413\n",
      "Epoch 76/300\n",
      "21/21 [==============================] - 0s - loss: 0.0398 - val_loss: 0.0417\n",
      "Epoch 77/300\n",
      "21/21 [==============================] - 0s - loss: 0.0405 - val_loss: 0.0464\n",
      "Epoch 78/300\n",
      "21/21 [==============================] - 0s - loss: 0.0447 - val_loss: 0.1912\n",
      "Epoch 79/300\n",
      "21/21 [==============================] - 0s - loss: 0.1919 - val_loss: 0.1765\n",
      "Epoch 80/300\n",
      "21/21 [==============================] - 0s - loss: 0.1605 - val_loss: 0.0435\n",
      "Epoch 81/300\n",
      "21/21 [==============================] - 0s - loss: 0.0421 - val_loss: 0.0428\n",
      "Epoch 82/300\n",
      "21/21 [==============================] - 0s - loss: 0.0414 - val_loss: 0.0422\n",
      "Epoch 83/300\n",
      "21/21 [==============================] - 0s - loss: 0.0408 - val_loss: 0.0417\n",
      "Epoch 84/300\n",
      "21/21 [==============================] - 0s - loss: 0.0403 - val_loss: 0.0413\n",
      "Epoch 85/300\n",
      "21/21 [==============================] - 0s - loss: 0.0398 - val_loss: 0.0409\n",
      "Epoch 86/300\n",
      "21/21 [==============================] - 0s - loss: 0.0395 - val_loss: 0.0405\n",
      "Epoch 87/300\n",
      "21/21 [==============================] - 0s - loss: 0.0391 - val_loss: 0.0402\n",
      "Epoch 88/300\n",
      "21/21 [==============================] - 0s - loss: 0.0388 - val_loss: 0.0399\n",
      "Epoch 89/300\n",
      "21/21 [==============================] - 0s - loss: 0.0385 - val_loss: 0.0396\n",
      "Epoch 90/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s - loss: 0.0382 - val_loss: 0.0394\n",
      "Epoch 91/300\n",
      "21/21 [==============================] - 0s - loss: 0.0380 - val_loss: 0.0392\n",
      "Epoch 92/300\n",
      "21/21 [==============================] - 0s - loss: 0.0377 - val_loss: 0.0389\n",
      "Epoch 93/300\n",
      "21/21 [==============================] - 0s - loss: 0.0375 - val_loss: 0.0387\n",
      "Epoch 94/300\n",
      "21/21 [==============================] - 0s - loss: 0.0373 - val_loss: 0.0385\n",
      "Epoch 95/300\n",
      "21/21 [==============================] - 0s - loss: 0.0371 - val_loss: 0.0383\n",
      "Epoch 96/300\n",
      "21/21 [==============================] - 0s - loss: 0.0369 - val_loss: 0.0381\n",
      "Epoch 97/300\n",
      "21/21 [==============================] - 0s - loss: 0.0367 - val_loss: 0.0380\n",
      "Epoch 98/300\n",
      "21/21 [==============================] - 0s - loss: 0.0366 - val_loss: 0.0378\n",
      "Epoch 99/300\n",
      "21/21 [==============================] - 0s - loss: 0.0364 - val_loss: 0.0376\n",
      "Epoch 100/300\n",
      "21/21 [==============================] - 0s - loss: 0.0362 - val_loss: 0.0374\n",
      "Epoch 101/300\n",
      "21/21 [==============================] - 0s - loss: 0.0361 - val_loss: 0.0373\n",
      "Epoch 102/300\n",
      "21/21 [==============================] - 0s - loss: 0.0359 - val_loss: 0.0371\n",
      "Epoch 103/300\n",
      "21/21 [==============================] - 0s - loss: 0.0357 - val_loss: 0.0370\n",
      "Epoch 104/300\n",
      "21/21 [==============================] - 0s - loss: 0.0356 - val_loss: 0.0368\n",
      "Epoch 105/300\n",
      "21/21 [==============================] - 0s - loss: 0.0354 - val_loss: 0.0366\n",
      "Epoch 106/300\n",
      "21/21 [==============================] - 0s - loss: 0.0353 - val_loss: 0.0365\n",
      "Epoch 107/300\n",
      "21/21 [==============================] - 0s - loss: 0.0351 - val_loss: 0.0363\n",
      "Epoch 108/300\n",
      "21/21 [==============================] - 0s - loss: 0.0349 - val_loss: 0.0362\n",
      "Epoch 109/300\n",
      "21/21 [==============================] - 0s - loss: 0.0348 - val_loss: 0.0360\n",
      "Epoch 110/300\n",
      "21/21 [==============================] - 0s - loss: 0.0346 - val_loss: 0.0359\n",
      "Epoch 111/300\n",
      "21/21 [==============================] - 0s - loss: 0.0345 - val_loss: 0.0357\n",
      "Epoch 112/300\n",
      "21/21 [==============================] - 0s - loss: 0.0343 - val_loss: 0.0356\n",
      "Epoch 113/300\n",
      "21/21 [==============================] - 0s - loss: 0.0342 - val_loss: 0.0354\n",
      "Epoch 114/300\n",
      "21/21 [==============================] - 0s - loss: 0.0340 - val_loss: 0.0352\n",
      "Epoch 115/300\n",
      "21/21 [==============================] - 0s - loss: 0.0339 - val_loss: 0.0351\n",
      "Epoch 116/300\n",
      "21/21 [==============================] - 0s - loss: 0.0337 - val_loss: 0.0349\n",
      "Epoch 117/300\n",
      "21/21 [==============================] - 0s - loss: 0.0335 - val_loss: 0.0348\n",
      "Epoch 118/300\n",
      "21/21 [==============================] - 0s - loss: 0.0334 - val_loss: 0.0346\n",
      "Epoch 119/300\n",
      "21/21 [==============================] - 0s - loss: 0.0332 - val_loss: 0.0345\n",
      "Epoch 120/300\n",
      "21/21 [==============================] - 0s - loss: 0.0331 - val_loss: 0.0343\n",
      "Epoch 121/300\n",
      "21/21 [==============================] - 1s - loss: 0.0329 - val_loss: 0.0341\n",
      "Epoch 122/300\n",
      "21/21 [==============================] - 0s - loss: 0.0327 - val_loss: 0.0340\n",
      "Epoch 123/300\n",
      "21/21 [==============================] - 0s - loss: 0.0326 - val_loss: 0.0338\n",
      "Epoch 124/300\n",
      "21/21 [==============================] - 0s - loss: 0.0324 - val_loss: 0.0336\n",
      "Epoch 125/300\n",
      "21/21 [==============================] - 0s - loss: 0.0322 - val_loss: 0.0335\n",
      "Epoch 126/300\n",
      "21/21 [==============================] - 0s - loss: 0.0320 - val_loss: 0.0333\n",
      "Epoch 127/300\n",
      "21/21 [==============================] - 0s - loss: 0.0319 - val_loss: 0.0331\n",
      "Epoch 128/300\n",
      "21/21 [==============================] - 0s - loss: 0.0317 - val_loss: 0.0329\n",
      "Epoch 129/300\n",
      "21/21 [==============================] - 0s - loss: 0.0315 - val_loss: 0.0328\n",
      "Epoch 130/300\n",
      "21/21 [==============================] - 0s - loss: 0.0313 - val_loss: 0.0326\n",
      "Epoch 131/300\n",
      "21/21 [==============================] - 0s - loss: 0.0311 - val_loss: 0.0324\n",
      "Epoch 132/300\n",
      "21/21 [==============================] - 0s - loss: 0.0310 - val_loss: 0.0322\n",
      "Epoch 133/300\n",
      "21/21 [==============================] - 0s - loss: 0.0308 - val_loss: 0.0320\n",
      "Epoch 134/300\n",
      "21/21 [==============================] - 0s - loss: 0.0306 - val_loss: 0.0318\n",
      "Epoch 135/300\n",
      "21/21 [==============================] - 0s - loss: 0.0304 - val_loss: 0.0317\n",
      "Epoch 136/300\n",
      "21/21 [==============================] - 0s - loss: 0.0302 - val_loss: 0.0315\n",
      "Epoch 137/300\n",
      "21/21 [==============================] - 0s - loss: 0.0300 - val_loss: 0.0313\n",
      "Epoch 138/300\n",
      "21/21 [==============================] - 0s - loss: 0.0298 - val_loss: 0.0311\n",
      "Epoch 139/300\n",
      "21/21 [==============================] - 0s - loss: 0.0296 - val_loss: 0.0309\n",
      "Epoch 140/300\n",
      "21/21 [==============================] - 0s - loss: 0.0294 - val_loss: 0.0307\n",
      "Epoch 141/300\n",
      "21/21 [==============================] - 0s - loss: 0.0292 - val_loss: 0.0305\n",
      "Epoch 142/300\n",
      "21/21 [==============================] - 0s - loss: 0.0290 - val_loss: 0.0303\n",
      "Epoch 143/300\n",
      "21/21 [==============================] - 0s - loss: 0.0288 - val_loss: 0.0301\n",
      "Epoch 144/300\n",
      "21/21 [==============================] - 0s - loss: 0.0286 - val_loss: 0.0299\n",
      "Epoch 145/300\n",
      "21/21 [==============================] - 0s - loss: 0.0283 - val_loss: 0.0297\n",
      "Epoch 146/300\n",
      "21/21 [==============================] - 0s - loss: 0.0281 - val_loss: 0.0295\n",
      "Epoch 147/300\n",
      "21/21 [==============================] - 0s - loss: 0.0279 - val_loss: 0.0292\n",
      "Epoch 148/300\n",
      "21/21 [==============================] - 0s - loss: 0.0277 - val_loss: 0.0290\n",
      "Epoch 149/300\n",
      "21/21 [==============================] - 0s - loss: 0.0275 - val_loss: 0.0288\n",
      "Epoch 150/300\n",
      "21/21 [==============================] - 0s - loss: 0.0273 - val_loss: 0.0286\n",
      "Epoch 151/300\n",
      "21/21 [==============================] - 0s - loss: 0.0270 - val_loss: 0.0284\n",
      "Epoch 152/300\n",
      "21/21 [==============================] - 0s - loss: 0.0268 - val_loss: 0.0282\n",
      "Epoch 153/300\n",
      "21/21 [==============================] - 0s - loss: 0.0266 - val_loss: 0.0280\n",
      "Epoch 154/300\n",
      "21/21 [==============================] - 0s - loss: 0.0264 - val_loss: 0.0277\n",
      "Epoch 155/300\n",
      "21/21 [==============================] - 0s - loss: 0.0261 - val_loss: 0.0275\n",
      "Epoch 156/300\n",
      "21/21 [==============================] - 0s - loss: 0.0259 - val_loss: 0.0273\n",
      "Epoch 157/300\n",
      "21/21 [==============================] - 0s - loss: 0.0257 - val_loss: 0.0271\n",
      "Epoch 158/300\n",
      "21/21 [==============================] - 0s - loss: 0.0254 - val_loss: 0.0269\n",
      "Epoch 159/300\n",
      "21/21 [==============================] - 0s - loss: 0.0252 - val_loss: 0.0266\n",
      "Epoch 160/300\n",
      "21/21 [==============================] - 0s - loss: 0.0250 - val_loss: 0.0264\n",
      "Epoch 161/300\n",
      "21/21 [==============================] - 0s - loss: 0.0247 - val_loss: 0.0262\n",
      "Epoch 162/300\n",
      "21/21 [==============================] - 0s - loss: 0.0245 - val_loss: 0.0259\n",
      "Epoch 163/300\n",
      "21/21 [==============================] - 0s - loss: 0.0243 - val_loss: 0.0257\n",
      "Epoch 164/300\n",
      "21/21 [==============================] - 0s - loss: 0.0240 - val_loss: 0.0255\n",
      "Epoch 165/300\n",
      "21/21 [==============================] - 0s - loss: 0.0238 - val_loss: 0.0252\n",
      "Epoch 166/300\n",
      "21/21 [==============================] - 0s - loss: 0.0235 - val_loss: 0.0250\n",
      "Epoch 167/300\n",
      "21/21 [==============================] - 0s - loss: 0.0233 - val_loss: 0.0248\n",
      "Epoch 168/300\n",
      "21/21 [==============================] - 0s - loss: 0.0231 - val_loss: 0.0246\n",
      "Epoch 169/300\n",
      "21/21 [==============================] - 0s - loss: 0.0228 - val_loss: 0.0243\n",
      "Epoch 170/300\n",
      "21/21 [==============================] - 0s - loss: 0.0226 - val_loss: 0.0241\n",
      "Epoch 171/300\n",
      "21/21 [==============================] - 0s - loss: 0.0223 - val_loss: 0.0239\n",
      "Epoch 172/300\n",
      "21/21 [==============================] - 0s - loss: 0.0221 - val_loss: 0.0236\n",
      "Epoch 173/300\n",
      "21/21 [==============================] - 0s - loss: 0.0218 - val_loss: 0.0234\n",
      "Epoch 174/300\n",
      "21/21 [==============================] - 0s - loss: 0.0216 - val_loss: 0.0232\n",
      "Epoch 175/300\n",
      "21/21 [==============================] - 0s - loss: 0.0214 - val_loss: 0.0229\n",
      "Epoch 176/300\n",
      "21/21 [==============================] - 0s - loss: 0.0211 - val_loss: 0.0227\n",
      "Epoch 177/300\n",
      "21/21 [==============================] - 0s - loss: 0.0209 - val_loss: 0.0225\n",
      "Epoch 178/300\n",
      "21/21 [==============================] - 0s - loss: 0.0206 - val_loss: 0.0222\n",
      "Epoch 179/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s - loss: 0.0204 - val_loss: 0.0220\n",
      "Epoch 180/300\n",
      "21/21 [==============================] - 0s - loss: 0.0201 - val_loss: 0.0218\n",
      "Epoch 181/300\n",
      "21/21 [==============================] - 0s - loss: 0.0199 - val_loss: 0.0215\n",
      "Epoch 182/300\n",
      "21/21 [==============================] - 1s - loss: 0.0197 - val_loss: 0.0213\n",
      "Epoch 183/300\n",
      "21/21 [==============================] - 0s - loss: 0.0194 - val_loss: 0.0211\n",
      "Epoch 184/300\n",
      "21/21 [==============================] - 0s - loss: 0.0192 - val_loss: 0.0208\n",
      "Epoch 185/300\n",
      "21/21 [==============================] - 0s - loss: 0.0189 - val_loss: 0.0206\n",
      "Epoch 186/300\n",
      "21/21 [==============================] - 0s - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 187/300\n",
      "21/21 [==============================] - 0s - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 188/300\n",
      "21/21 [==============================] - 0s - loss: 0.0182 - val_loss: 0.0199\n",
      "Epoch 189/300\n",
      "21/21 [==============================] - 0s - loss: 0.0180 - val_loss: 0.0197\n",
      "Epoch 190/300\n",
      "21/21 [==============================] - 0s - loss: 0.0178 - val_loss: 0.0195\n",
      "Epoch 191/300\n",
      "21/21 [==============================] - 0s - loss: 0.0175 - val_loss: 0.0193\n",
      "Epoch 192/300\n",
      "21/21 [==============================] - 0s - loss: 0.0173 - val_loss: 0.0191\n",
      "Epoch 193/300\n",
      "21/21 [==============================] - 0s - loss: 0.0171 - val_loss: 0.0188\n",
      "Epoch 194/300\n",
      "21/21 [==============================] - 0s - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 195/300\n",
      "21/21 [==============================] - 0s - loss: 0.0166 - val_loss: 0.0184\n",
      "Epoch 196/300\n",
      "21/21 [==============================] - 0s - loss: 0.0164 - val_loss: 0.0182\n",
      "Epoch 197/300\n",
      "21/21 [==============================] - 0s - loss: 0.0162 - val_loss: 0.0180\n",
      "Epoch 198/300\n",
      "21/21 [==============================] - 0s - loss: 0.0160 - val_loss: 0.0178\n",
      "Epoch 199/300\n",
      "21/21 [==============================] - 0s - loss: 0.0157 - val_loss: 0.0176\n",
      "Epoch 200/300\n",
      "21/21 [==============================] - 0s - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 201/300\n",
      "21/21 [==============================] - 0s - loss: 0.0153 - val_loss: 0.0172\n",
      "Epoch 202/300\n",
      "21/21 [==============================] - 0s - loss: 0.0151 - val_loss: 0.0170\n",
      "Epoch 203/300\n",
      "21/21 [==============================] - 0s - loss: 0.0149 - val_loss: 0.0168\n",
      "Epoch 204/300\n",
      "21/21 [==============================] - 0s - loss: 0.0147 - val_loss: 0.0166\n",
      "Epoch 205/300\n",
      "21/21 [==============================] - 0s - loss: 0.0145 - val_loss: 0.0164\n",
      "Epoch 206/300\n",
      "21/21 [==============================] - 0s - loss: 0.0143 - val_loss: 0.0162\n",
      "Epoch 207/300\n",
      "21/21 [==============================] - 0s - loss: 0.0141 - val_loss: 0.0161\n",
      "Epoch 208/300\n",
      "21/21 [==============================] - 0s - loss: 0.0139 - val_loss: 0.0159\n",
      "Epoch 209/300\n",
      "21/21 [==============================] - 0s - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 210/300\n",
      "21/21 [==============================] - 0s - loss: 0.0135 - val_loss: 0.0155\n",
      "Epoch 211/300\n",
      "21/21 [==============================] - 0s - loss: 0.0133 - val_loss: 0.0154\n",
      "Epoch 212/300\n",
      "21/21 [==============================] - 0s - loss: 0.0131 - val_loss: 0.0152\n",
      "Epoch 213/300\n",
      "21/21 [==============================] - 0s - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 214/300\n",
      "21/21 [==============================] - 0s - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 215/300\n",
      "21/21 [==============================] - 0s - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 216/300\n",
      "21/21 [==============================] - 0s - loss: 0.0124 - val_loss: 0.0145\n",
      "Epoch 217/300\n",
      "21/21 [==============================] - 0s - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 218/300\n",
      "21/21 [==============================] - 0s - loss: 0.0120 - val_loss: 0.0142\n",
      "Epoch 219/300\n",
      "21/21 [==============================] - 0s - loss: 0.0118 - val_loss: 0.0141\n",
      "Epoch 220/300\n",
      "21/21 [==============================] - 0s - loss: 0.0117 - val_loss: 0.0139\n",
      "Epoch 221/300\n",
      "21/21 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 222/300\n",
      "21/21 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0136\n",
      "Epoch 223/300\n",
      "21/21 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 224/300\n",
      "21/21 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 225/300\n",
      "21/21 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 226/300\n",
      "21/21 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 227/300\n",
      "21/21 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 228/300\n",
      "21/21 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 229/300\n",
      "21/21 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 230/300\n",
      "21/21 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 231/300\n",
      "21/21 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0127\n",
      "Epoch 232/300\n",
      "21/21 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0124\n",
      "Epoch 233/300\n",
      "21/21 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 234/300\n",
      "21/21 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 235/300\n",
      "21/21 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 236/300\n",
      "21/21 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0117\n",
      "Epoch 237/300\n",
      "21/21 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0116\n",
      "Epoch 238/300\n",
      "21/21 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0115\n",
      "Epoch 239/300\n",
      "21/21 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0114\n",
      "Epoch 240/300\n",
      "21/21 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0112\n",
      "Epoch 241/300\n",
      "21/21 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0111\n",
      "Epoch 242/300\n",
      "21/21 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0110\n",
      "Epoch 243/300\n",
      "21/21 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 244/300\n",
      "21/21 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 245/300\n",
      "21/21 [==============================] - 0s - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 246/300\n",
      "21/21 [==============================] - 0s - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 247/300\n",
      "21/21 [==============================] - 0s - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 248/300\n",
      "21/21 [==============================] - 0s - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 249/300\n",
      "21/21 [==============================] - 0s - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 250/300\n",
      "21/21 [==============================] - 0s - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 251/300\n",
      "21/21 [==============================] - 0s - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 252/300\n",
      "21/21 [==============================] - 0s - loss: 0.0073 - val_loss: 0.0098\n",
      "Epoch 253/300\n",
      "21/21 [==============================] - 0s - loss: 0.0071 - val_loss: 0.0096\n",
      "Epoch 254/300\n",
      "21/21 [==============================] - 0s - loss: 0.0070 - val_loss: 0.0095\n",
      "Epoch 255/300\n",
      "21/21 [==============================] - 0s - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 256/300\n",
      "21/21 [==============================] - 0s - loss: 0.0068 - val_loss: 0.0093\n",
      "Epoch 257/300\n",
      "21/21 [==============================] - 0s - loss: 0.0067 - val_loss: 0.0091\n",
      "Epoch 258/300\n",
      "21/21 [==============================] - 0s - loss: 0.0066 - val_loss: 0.0090\n",
      "Epoch 259/300\n",
      "21/21 [==============================] - 0s - loss: 0.0065 - val_loss: 0.0089\n",
      "Epoch 260/300\n",
      "21/21 [==============================] - 0s - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 261/300\n",
      "21/21 [==============================] - 0s - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 262/300\n",
      "21/21 [==============================] - 0s - loss: 0.0061 - val_loss: 0.0085\n",
      "Epoch 263/300\n",
      "21/21 [==============================] - 0s - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 264/300\n",
      "21/21 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0083\n",
      "Epoch 265/300\n",
      "21/21 [==============================] - 0s - loss: 0.0058 - val_loss: 0.0081\n",
      "Epoch 266/300\n",
      "21/21 [==============================] - 0s - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 267/300\n",
      "21/21 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 268/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s - loss: 0.0055 - val_loss: 0.0078\n",
      "Epoch 269/300\n",
      "21/21 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 270/300\n",
      "21/21 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0075\n",
      "Epoch 271/300\n",
      "21/21 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 272/300\n",
      "21/21 [==============================] - 0s - loss: 0.0051 - val_loss: 0.0073\n",
      "Epoch 273/300\n",
      "21/21 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0072\n",
      "Epoch 274/300\n",
      "21/21 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0071\n",
      "Epoch 275/300\n",
      "21/21 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0069\n",
      "Epoch 276/300\n",
      "21/21 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0068\n",
      "Epoch 277/300\n",
      "21/21 [==============================] - 0s - loss: 0.0047 - val_loss: 0.0067\n",
      "Epoch 278/300\n",
      "21/21 [==============================] - 0s - loss: 0.0046 - val_loss: 0.0066\n",
      "Epoch 279/300\n",
      "21/21 [==============================] - 0s - loss: 0.0045 - val_loss: 0.0065\n",
      "Epoch 280/300\n",
      "21/21 [==============================] - 0s - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 281/300\n",
      "21/21 [==============================] - 0s - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 282/300\n",
      "21/21 [==============================] - 0s - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 283/300\n",
      "21/21 [==============================] - 0s - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 284/300\n",
      "21/21 [==============================] - 0s - loss: 0.0040 - val_loss: 0.0059\n",
      "Epoch 285/300\n",
      "21/21 [==============================] - 0s - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 286/300\n",
      "21/21 [==============================] - 0s - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 287/300\n",
      "21/21 [==============================] - 0s - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 288/300\n",
      "21/21 [==============================] - 0s - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 289/300\n",
      "21/21 [==============================] - 0s - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 290/300\n",
      "21/21 [==============================] - 0s - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 291/300\n",
      "21/21 [==============================] - 0s - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 292/300\n",
      "21/21 [==============================] - 0s - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 293/300\n",
      "21/21 [==============================] - 0s - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 294/300\n",
      "21/21 [==============================] - 0s - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 295/300\n",
      "21/21 [==============================] - 0s - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 296/300\n",
      "21/21 [==============================] - 0s - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 297/300\n",
      "21/21 [==============================] - 0s - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 298/300\n",
      "21/21 [==============================] - 0s - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 299/300\n",
      "21/21 [==============================] - 0s - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 300/300\n",
      "21/21 [==============================] - 0s - loss: 0.0028 - val_loss: 0.0043\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "#### Repeat ::: Re-run this block until val_loss reaches a lower value\n",
    "####\n",
    "\n",
    "history=model.fit(X_train, y_train, validation_split=0.15 ,batch_size=32, epochs=300,callbacks=callbacks_list)\n",
    "all_history[0]=all_history[0]+ history.history['loss']\n",
    "all_history[1]=all_history[1]+ history.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effad9cfa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for loss\n",
    "#plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.plot(all_history[0])\n",
    "plt.plot(all_history[1])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.evaluate(X_test, y_test, batch_size=1)\n",
    "# print(\"score: \"+str(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Test the result\n",
    "\n",
    "startChar='5'\n",
    "sentenceLen=50\n",
    "X_test=np.zeros( (1,sentenceLen,max_features), dtype=int)\n",
    "dex=dct.index(startChar)\n",
    "X_test[0,0,dex]=1\n",
    "print(X_test[0,0:10,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_test.shape[1]):\n",
    "    predict_y=model.predict(X_test)\n",
    "    predict_y_dex=np.argmax(predict_y[0,i,...])\n",
    "    if i+1 < X_test.shape[1] :\n",
    "        X_test[0,i+1,predict_y_dex]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0,0:10,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\n",
    "for i in range(X_test.shape[1]):\n",
    "    tmp=np.where( X_test[0,i,...]==1)\n",
    "    sentence=sentence+inv_mydict[int(tmp[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56789012345678901234567890123456789012345678901234\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
